{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interceptor\n",
    "\n",
    "In this example, you gonna learn how to use `Interceptor` to capture intermediate values in the execution of a PyTorch module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # PyTorch\n",
    "\n",
    "from pytorch_probing import Interceptor # Intercepts intermediate values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gonna start creating a example a module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, n_hidden=0):\n",
    "        super().__init__()\n",
    "        self.linear1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        if n_hidden > 0:\n",
    "            layers = []\n",
    "            for _ in range(n_hidden):\n",
    "                layers.append(torch.nn.Linear(hidden_size, hidden_size))\n",
    "                layers.append(torch.nn.ReLU())\n",
    "            self.hidden_layers = torch.nn.Sequential(*layers)\n",
    "        self._n_hidden = n_hidden\n",
    "\n",
    "        self.linear2 = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        if self._n_hidden > 0:\n",
    "            x = self.hidden_layers(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we gonna use 2 hidden layers between the first and last layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExampleModel(\n",
       "  (linear1): Linear(in_features=2, out_features=3, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (hidden_layers): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=3, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=3, out_features=3, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (linear2): Linear(in_features=3, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 2\n",
    "hidden_size = 3\n",
    "output_size = 1\n",
    "n_hidden = 2\n",
    "\n",
    "model = ExampleModel(input_size, hidden_size, output_size, n_hidden)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Than, we gonna pass our created module to a Interceptor, with the paths of the submodules we wanna get its outputs. Notices that we can use \".\" to get inner submodules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Interceptor(\n",
       "  (_module): ExampleModel(\n",
       "    (linear1): InterceptorLayer(\n",
       "      (_module): Linear(in_features=2, out_features=3, bias=True)\n",
       "    )\n",
       "    (relu): ReLU()\n",
       "    (hidden_layers): Sequential(\n",
       "      (0): Linear(in_features=3, out_features=3, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): InterceptorLayer(\n",
       "        (_module): Linear(in_features=3, out_features=3, bias=True)\n",
       "      )\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (linear2): InterceptorLayer(\n",
       "      (_module): Linear(in_features=3, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = [\"linear1\", \"hidden_layers.2\", \"linear2\"]\n",
    "\n",
    "intercepted_model = Interceptor(model, paths, detach=False)\n",
    "intercepted_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Interceptor modifies in-place the original module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExampleModel(\n",
       "  (linear1): InterceptorLayer(\n",
       "    (_module): Linear(in_features=2, out_features=3, bias=True)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (hidden_layers): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=3, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): InterceptorLayer(\n",
       "      (_module): Linear(in_features=3, out_features=3, bias=True)\n",
       "    )\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (linear2): InterceptorLayer(\n",
       "    (_module): Linear(in_features=3, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass a example input throught the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn([10, 2])\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = intercepted_model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1188],\n",
       "        [-0.1146],\n",
       "        [-0.1182],\n",
       "        [-0.1188],\n",
       "        [-0.1169],\n",
       "        [-0.0354],\n",
       "        [-0.0088],\n",
       "        [-0.1188],\n",
       "        [-0.0176],\n",
       "        [-0.0311]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the interceptor captures the required outputs and stores then in the \"outputs\" attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear1': tensor([[-2.0626e-01, -3.4000e-01, -7.1013e-01],\n",
       "         [ 1.4269e-01,  4.0346e-01, -2.8771e-01],\n",
       "         [ 1.2523e-03,  3.7725e-02, -4.4547e-01],\n",
       "         [-9.4030e-02, -4.1919e-01, -5.0774e-01],\n",
       "         [ 2.8304e-02,  1.4661e-01, -4.2343e-01],\n",
       "         [ 4.4011e-01,  1.2838e+00,  2.0783e-02],\n",
       "         [ 5.2744e-01,  1.4350e+00,  1.3378e-01],\n",
       "         [-4.4810e-01, -1.0078e+00, -9.7100e-01],\n",
       "         [ 5.7576e-01,  1.2486e+00,  2.5274e-01],\n",
       "         [ 5.0058e-01,  1.2254e+00,  1.3309e-01]]),\n",
       " 'hidden_layers.2': tensor([[-0.1331, -0.3591,  0.5654],\n",
       "         [-0.1674, -0.3851,  0.5777],\n",
       "         [-0.1380, -0.3628,  0.5672],\n",
       "         [-0.1331, -0.3591,  0.5654],\n",
       "         [-0.1489, -0.3711,  0.5711],\n",
       "         [-0.3302, -0.4968,  0.8093],\n",
       "         [-0.3599, -0.5250,  0.8870],\n",
       "         [-0.1331, -0.3591,  0.5654],\n",
       "         [-0.3189, -0.4983,  0.8614],\n",
       "         [-0.3161, -0.4908,  0.8217]]),\n",
       " 'linear2': tensor([[-0.1188],\n",
       "         [-0.1146],\n",
       "         [-0.1182],\n",
       "         [-0.1188],\n",
       "         [-0.1169],\n",
       "         [-0.0354],\n",
       "         [-0.0088],\n",
       "         [-0.1188],\n",
       "         [-0.0176],\n",
       "         [-0.0311]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercepted_model.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clean this outputs with the `interceptor_clear` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear1': None, 'hidden_layers.2': None, 'linear2': None}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercepted_model.interceptor_clear()\n",
    "intercepted_model.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And return the model to its original state with the reduce method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExampleModel(\n",
       "  (linear1): Linear(in_features=2, out_features=3, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (hidden_layers): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=3, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=3, out_features=3, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (linear2): Linear(in_features=3, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercepted_model.reduce()\n",
    "\n",
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
